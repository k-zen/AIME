package io.aime.plugins.parsetika;

// AIME
import io.aime.metadata.DocMetadata;
import io.aime.parse.HtmlMetaTags;
import io.aime.parse.HtmlParseFilters;
import io.aime.parse.Outlink;
import io.aime.parse.OutlinkExtractor;
import io.aime.parse.Parse;
import io.aime.parse.ParseData;
import io.aime.parse.ParseImplementation;
import io.aime.parse.ParseResult;
import io.aime.parse.ParseStatus;
import io.aime.protocol.Content;
import io.aime.util.AIMEConstants;
import io.aime.util.DOMBuilder;
import io.aime.util.DOMContentUtils;
import io.aime.util.HtmlMetaProcessor;
import io.aime.util.GeneralUtilities;

// Apache Hadoop
import org.apache.hadoop.conf.Configuration;

// Apache HTML
import org.apache.html.dom.HTMLDocumentImpl;

// Apache Tika
import org.apache.tika.config.TikaConfig;
import org.apache.tika.metadata.Metadata;
import org.apache.tika.mime.MediaType;
import org.apache.tika.parser.ParseContext;
import org.apache.tika.parser.Parser;

// DOM
import org.w3c.dom.DocumentFragment;

// IO
import java.io.ByteArrayInputStream;

// Log4j
import org.apache.log4j.Logger;

// Net
import java.net.MalformedURLException;
import java.net.URL;

// Util
import java.util.ArrayList;
import java.util.Map;

/**
 * Wrapper for Tika parsers.
 * <p>Mimics the HTMLParser but using the XHTML representation returned by Tika
 * as SAX events.</p>
 *
 * @author K-Zen
 */
public class TikaParser implements io.aime.parse.Parser {

    public static final Logger LOG = Logger.getLogger(TikaParser.class.getName());
    private Configuration conf;
    private TikaConfig tikaConfig = null;
    private DOMContentUtils utils;
    private HtmlParseFilters htmlParseFilters;
    private String cachingPolicy;

    @Override
    public ParseResult getParseResult(Content content) {
        String mimeType = content.getContentType();
        URL base;

        try {
            base = new URL(content.getBaseUrl());
        }
        catch (MalformedURLException e) {
            return new ParseStatus(e).getEmptyParseResult(content.getUrl(), getConf());
        }

        // Get the right parser using the mime type as a clue.
        Parser parser = tikaConfig.getParser(MediaType.parse(mimeType));
        byte[] raw = content.getContent();

        // If Tika can't find a parser for the document, then it means it's probably a not-supported
        // binary file. We should stored anyway.
        if (parser == null) {
            return new ParseStatus(ParseStatus.NOTPARSED, "Can't retrieve Tika parser for mime-type " + mimeType).getEmptyParseResult(content.getUrl(), getConf());
        }

        if (LOG.isDebugEnabled()) {
            LOG.debug("Using Tika parser " + parser.getClass().getName() + " for mime-type " + mimeType);
        }

        Metadata tikamd = new Metadata();
        HTMLDocumentImpl doc = new HTMLDocumentImpl();
        doc.setErrorChecking(false);
        DocumentFragment root = doc.createDocumentFragment();
        DOMBuilder domhandler = new DOMBuilder(doc, root);
        ParseContext context = new ParseContext();

        try {
            parser.parse(new ByteArrayInputStream(raw), domhandler, tikamd, context);
        }
        catch (Exception e) {
            LOG.error("Error parsing " + content.getUrl(), e);
            return new ParseStatus(ParseStatus.FAILED, e.getMessage()).getEmptyParseResult(content.getUrl(), getConf());
        }

        HtmlMetaTags metaTags = new HtmlMetaTags();
        String text = new String();
        String title = new String();
        Outlink[] outlinks = new Outlink[0];
        DocMetadata metadata = new DocMetadata();

        // we have converted the sax events generated by Tika into a DOM object
        // so we can now use the usual HTML resources from Nutch
        // get meta directives
        HtmlMetaProcessor.getMetaTags(metaTags, root, base);
        if (LOG.isTraceEnabled()) {
            LOG.trace("Meta tags for " + base + ": " + metaTags.toString());
        }

        // check meta directives
        if (!metaTags.getNoIndex()) { // okay to index
            text = utils.getText(root); // extract text
            title = utils.getTitle(root); // extract title
            // If the title is empty, then use the first 6 words of the document's text.
            if ((title.isEmpty() || title.split("\\s").length < 2) && !text.isEmpty()) {
                StringBuilder tmp = new StringBuilder();
                byte counter = 0;
                for (String word : text.split("\\s")) {
                    if (counter == 8) {
                        break;
                    }

                    tmp.append(word).append(" ");
                    counter++;
                }
                title = tmp.append(" ...").toString();
            }
        }

        if (!metaTags.getNoFollow()) { // okay to follow links
            ArrayList<Outlink> l = new ArrayList<Outlink>(); // extract outlinks
            URL baseTag = utils.getBase(root);
            utils.getOutlinks(baseTag != null ? baseTag : base, l, root);
            outlinks = l.toArray(new Outlink[l.size()]);
        }

        // Populate DocMetadata with Tika metadata.
        String[] TikaMDNames = tikamd.names();
        for (String tikaMDName : TikaMDNames) {
            if (tikaMDName.equalsIgnoreCase(Metadata.TITLE)) {
                continue;
            }

            // TODO what if multivalued?
            metadata.add(tikaMDName, tikamd.get(tikaMDName));
        }

        // No outlinks? try OutlinkExtractor e.g works for mime types where no
        // explicit markup for anchors
        if (outlinks.length == 0) {
            outlinks = OutlinkExtractor.getOutlinks(text, getConf());
        }

        ParseStatus status = new ParseStatus(ParseStatus.SUCCESS);
        if (metaTags.getRefresh()) {
            status.setMinorCode(ParseStatus.SUCCESS_REDIRECT);
            status.setArgs(new String[]{metaTags.getRefreshHref().toString(), Integer.toString(metaTags.getRefreshTime())});
        }

        ParseData parseData = new ParseData(status, title, outlinks, content.getMetadata(), metadata);
        ParseResult parseResult = ParseResult.createParseResult(content.getUrl(), new ParseImplementation(text, parseData));
        ParseResult filteredParse = htmlParseFilters.filter(content, parseResult, metaTags, root); // Run filters on parsed data.
        if (metaTags.getNoCache()) { // not okay to cache
            for (Map.Entry<org.apache.hadoop.io.Text, Parse> entry : filteredParse) {
                entry.getValue().getData().getParseMeta().set(AIMEConstants.CACHING_FORBIDDEN_KEY.getStringConstant(), cachingPolicy);
            }
        }

        if (LOG.isInfoEnabled()) {
            LOG.info("Parsing File: " + GeneralUtilities.trimURL(content.getUrl(), 120));
        }

        return filteredParse;
    }

    @Override
    public void setConf(Configuration conf) {
        this.conf = conf;
        tikaConfig = null;

        // do we want a custom Tika configuration file
        // deprecated since Tika 0.7 which is based on 
        // a service provider based configuration
        String customConfFile = conf.get("tika.config.file");
        if (customConfFile != null) {
            try {
                // see if a Tika config file can be found in the job file
                URL customTikaConfig = conf.getResource(customConfFile);

                if (customTikaConfig != null) {
                    tikaConfig = new TikaConfig(customTikaConfig);
                }
            }
            catch (Exception e1) {
                String message = "Problem loading custom Tika configuration from " + customConfFile;
                LOG.error(message, e1);
            }
        }
        else {
            try {
                tikaConfig = new TikaConfig(this.getClass().getClassLoader());
            }
            catch (Exception e2) {
                String message = "Problem loading default Tika configuration";
                LOG.error(message, e2);
            }
        }

        htmlParseFilters = new HtmlParseFilters(getConf());
        utils = new DOMContentUtils(conf);
        cachingPolicy = getConf().get("parser.caching.forbidden.policy", AIMEConstants.CACHING_FORBIDDEN_CONTENT.getStringConstant());
    }

    @Override
    public Configuration getConf() {
        return conf;
    }

    @Override
    public DocumentFragment getPageStructure(Content document) {
        throw new UnsupportedOperationException("Not supported yet.");
    }
}
